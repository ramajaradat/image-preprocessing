{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.5.5'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "human=cv2.imread(\"./data_2/human.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_copy=human.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line 2&3 use to dont get error when we close the output window\n",
    "cv2.imshow('human',human)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(510, 768, 3)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask\n",
    "mask=np.zeros(human.shape[:2], np.uint8) # mask=np.zeros(human.shape[:-1]) that same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat dummy array for fetures using\n",
    "bgd=np.zeros((1,65),np.float64) # creat background\n",
    "fgd=np.zeros((1,65),np.float64) # creat front background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to select region using openv => by using  selectro function \n",
    "# thes function help me to find thw w&h for the obj which i need\n",
    "rect=cv2.selectROI(human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('human',rect)\n",
    "cv2.waitKey(10)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,w,h=rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[34, 60, 67],\n",
       "        [31, 57, 64],\n",
       "        [29, 54, 64],\n",
       "        ...,\n",
       "        [30, 56, 63],\n",
       "        [32, 55, 63],\n",
       "        [32, 55, 63]],\n",
       "\n",
       "       [[34, 60, 67],\n",
       "        [34, 60, 67],\n",
       "        [33, 58, 68],\n",
       "        ...,\n",
       "        [28, 54, 61],\n",
       "        [32, 54, 65],\n",
       "        [32, 55, 63]],\n",
       "\n",
       "       [[36, 61, 71],\n",
       "        [35, 60, 70],\n",
       "        [33, 58, 68],\n",
       "        ...,\n",
       "        [28, 53, 63],\n",
       "        [33, 55, 67],\n",
       "        [34, 56, 67]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[37, 55, 38],\n",
       "        [38, 56, 39],\n",
       "        [35, 54, 37],\n",
       "        ...,\n",
       "        [54, 99, 82],\n",
       "        [51, 95, 78],\n",
       "        [46, 90, 73]],\n",
       "\n",
       "       [[36, 55, 36],\n",
       "        [37, 56, 37],\n",
       "        [35, 55, 36],\n",
       "        ...,\n",
       "        [53, 98, 82],\n",
       "        [50, 95, 79],\n",
       "        [46, 91, 75]],\n",
       "\n",
       "       [[35, 54, 35],\n",
       "        [37, 56, 37],\n",
       "        [35, 55, 36],\n",
       "        ...,\n",
       "        [50, 97, 81],\n",
       "        [48, 93, 77],\n",
       "        [43, 88, 72]]], dtype=uint8)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.rectangle(human_copy,(x,y),(x+w,y+h),(0,0,255),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"Human_ROI.png\",human_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " array([[2.08483387e-01, 1.28057734e-01, 3.20413790e-01, 1.94959354e-01,\n",
       "         1.48085735e-01, 3.67911840e+01, 6.39328200e+01, 7.93200077e+01,\n",
       "         2.89678475e+01, 5.13648104e+01, 4.55973370e+01, 4.52815737e+01,\n",
       "         1.00596537e+02, 8.22208824e+01, 3.53602978e+01, 8.42195864e+01,\n",
       "         6.55107936e+01, 5.41991720e+01, 9.89168191e+01, 1.03489208e+02,\n",
       "         4.82584597e+01, 5.75894429e+01, 6.95623710e+01, 5.75894429e+01,\n",
       "         9.49168047e+01, 1.14393149e+02, 6.95623710e+01, 1.14393149e+02,\n",
       "         1.60479047e+02, 7.49395376e+01, 7.63019703e+01, 5.23079547e+01,\n",
       "         7.63019703e+01, 1.64242857e+02, 5.38469914e+01, 5.23079547e+01,\n",
       "         5.38469914e+01, 1.04779324e+02, 2.62277945e+01, 2.24325721e+01,\n",
       "         2.37596293e+01, 2.24325721e+01, 2.85540328e+01, 2.63031838e+01,\n",
       "         2.37596293e+01, 2.63031838e+01, 3.08403381e+01, 5.95681555e+01,\n",
       "         3.89328910e+01, 3.78717729e+01, 3.89328910e+01, 5.66240257e+01,\n",
       "         5.41949125e+01, 3.78717729e+01, 5.41949125e+01, 6.06421964e+01,\n",
       "         2.34846361e+02, 2.36608461e+02, 2.27337646e+02, 2.36608461e+02,\n",
       "         3.14812105e+02, 1.75317057e+02, 2.27337646e+02, 1.75317057e+02,\n",
       "         3.81676320e+02]]),\n",
       " array([[ 1.41002172e-01,  5.89563350e-01,  1.48446462e-01,\n",
       "          1.73293305e-03,  1.19255083e-01,  7.99930760e+01,\n",
       "          9.58428250e+01,  1.74837632e+02,  5.04179673e+01,\n",
       "          5.55977230e+01,  1.96345229e+02,  1.22259125e+01,\n",
       "          1.33714239e+01,  6.61581717e+01,  5.30845070e+01,\n",
       "          8.99295775e+01,  9.31549296e+01,  2.45356120e+01,\n",
       "          3.00026607e+01,  1.24200982e+02,  8.44660503e+02,\n",
       "          9.61338188e+02,  5.01671543e+02,  9.61338188e+02,\n",
       "          1.18548300e+03,  5.35760009e+02,  5.01671543e+02,\n",
       "          5.35760009e+02,  7.75725757e+02,  1.50949791e+02,\n",
       "          1.37276563e+02,  1.87050738e+02,  1.37276563e+02,\n",
       "          1.33735462e+02,  1.79872432e+02,  1.87050738e+02,\n",
       "          1.79872432e+02,  3.21032587e+02,  1.13845379e+02,\n",
       "          7.52002078e+01,  6.26681473e+01,  7.52002078e+01,\n",
       "          7.96951584e+01,  2.79932079e+01,  6.26681473e+01,\n",
       "          2.79932079e+01,  4.02180506e+02,  8.72886332e+01,\n",
       "          2.83862329e+01,  8.34516961e+01,  2.83862329e+01,\n",
       "          5.84316604e+01,  3.46024598e+01,  8.34516961e+01,\n",
       "          3.46024598e+01,  1.05708391e+02,  1.62805015e+02,\n",
       "          1.50483634e+02,  3.60712299e+01,  1.50483634e+02,\n",
       "          1.76063644e+02, -3.56988565e+01,  3.60712299e+01,\n",
       "         -3.56988565e+01,  4.18353384e+02]]))"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# algorithm grabcut we cut original image according the rect image \n",
    "#5==num of iteration\n",
    "cv2.grabCut(human,mask,rect,bgd,fgd,5,cv2.GC_INIT_WITH_RECT)\n",
    "# this fun return 3 valuse one respect bgd,one respect values we find by ROI and the last one respect human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(510, 768)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.min(),mask.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1446581532004372"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the most of valuse is go to be 1.14 ==>white so background 0 mask=1 ,rect=2 \n",
    "mask.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creat mask2 we get 3values from grabcut 0,1,2\n",
    "mask2 = np.where((mask == 2 ) | (mask == 0), 0, 1).astype(\"uint8\")#last 0.1 is refer to white if true else black \n",
    "cv2.imwrite(\"mask.png\", mask*80)\n",
    "cv2.imwrite(\"mask2.png\", mask2*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3], dtype=uint8)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(mask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.ndim,mask2.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inference on original data (image),mask2 return just human so we take it\n",
    "human = human * mask2[:,:,np.newaxis]\n",
    "cv2.imwrite(\"result.png\", human)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Videos \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "haar_cascae_car=\"./data_2/haarcascade_car.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_class = cv2.CascadeClassifier (haar_cascae_car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read cars video using fun in cv => vieo capture\n",
    "cap= cv2.VideoCapture(\"./data_2/cars.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objec detection cars\n",
    "#open video inside loop to continue run video \n",
    "count=0\n",
    "while cap.isOpened():\n",
    "    count+=1\n",
    "    if count  % 10==0:# every 20 milliseconde        \n",
    "        ret,frame=cap.read()        \n",
    "        gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY) # convert each frame to gray\n",
    "        cars=car_class.detectMultiScale(gray, 1.1, 3)#calssification , detect for every frame\n",
    "        \n",
    "        for(x,y,w,h) in cars:\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),3)          \n",
    "            cv2.putText(frame,\"car\",(x,y),cv2.FONT_HERSHEY_SIMPLEX ,0.5, (0,0,255))  # fun control the put text like the type of font the coordinate ,...etc // note we take this argument from document\n",
    "        cv2.imshow(\"cars\",frame)\n",
    "    if cv2.waitKey(0) & 0xFF == ord(\"q\"):  # waitKey    \n",
    "        break \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
